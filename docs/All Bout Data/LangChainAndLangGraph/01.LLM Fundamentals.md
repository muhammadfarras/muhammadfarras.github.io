# Dasar LLM dengan LangChain

LLM atau _Large Language Model_ adalah algoritma yang terlatih untuk membaca atau menerima nilai masukan lalu memprediksi dan menghasilkan nilai keluaran dalam bentuk jawaban atas pertanyaan, dimana jawaban tersebut mirip dengan jawaban yang dikeluarkan oleh manusia.

**_Large_**, kata tersebut merujuk pada besarnya sebuah model dalam bentuk data pelatihan dan parameter yang digunakan saat proses belajar (pembuatan) model. Sebagai contoh, OpenAI's GPT-3 model beris 175 miliyar parameter yang dilatih lebih dari 45 _terrabytes_ data teks.

**_Language Model_**, sedangkan untuk LM, adalah sebuah algoritma komputer yang dilatih untuk menerima nilai masukan dalam bentuk text (bahasa manusia, umumnya menggunakan bahasa Inggris) dan menghasilkan serta memberikan jawaban dalam bentuk text.

Karena pada umumnya Model dilatih dengan data text yang menggunakan bahasa Inggris, sehingga input yang menggunakan bahasa Inggris menghasilkan jawaban yang lebih baik. Akan tetapi, perbedaan performa terhadap bahasa lain bahkan pada model yang dilatih dengan dominan menggunakan text bahasa Inggris tidak terlalu jauh. {==Peneliti menemukan bahwa LLM dapat merubah pengatahuan semantiknya kedalam bahasa lain.==}

Mari kita coba berikan input kedalam LLM.

!!! example

    ```cmd
    >>> The capital of Indonesia is _______
    ...Jakarta.
    ```

LLM (_saya menggunakan `llama3.2`_) menjawab pertanyaan sederhana dengan benar. Dibelakang layar, LLM mengestimasi probabilitas dari urutan kata atau kalimat yang sebelumnya diberikan pada saat pelatihan model.

Secara teknis, LLM memprediksi `token`, bukan kata ataupun kalimat. `Token` merepresentasikan nilai atomik dari kata, sub suku kata, atau bahkan kalimat tergantung dengan pendekatan tokenisasi yang digunakan. Sebagai contoh, 