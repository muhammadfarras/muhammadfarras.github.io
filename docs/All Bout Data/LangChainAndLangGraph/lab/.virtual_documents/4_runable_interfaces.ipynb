from langchain_ollama import ChatOllama
from StructuredOutputClass import JawabanTerstruktur


model = ChatOllama(model='llama3.2:latest', temperature=0).with_structured_output(JawabanTerstruktur)





model.invoke('What animal has the most poison venom ?')





question = ['What animal has the most posion venom ?', 'What snake has the most poisonous venom ?']
model.batch(question)





model_text = ChatOllama(model='llama3.2:latest', temperature=0)
question_list = ['Hello']
for data in model_text.stream(question_list):
    print (data.content, flush=True)
