# Dasar LLM dengan LangChain

!!! tip "Coretan pada catatan ini"

    Coratan pada catatan ini dapat dilihat pada lab [disini](disini)

Tantangan dalam membuat aplikasi LLM adalah bagaimana membangun struktur perintah untuk diberikan kesebuah model dan memproses prediksi dari model sehingga mendapatkan hasil yang akurat.

!!! warning "Proses Sederhana Aplikasi LLM"
    ![alt text](./assets/2.%20Struktursederhana-aplikasi-llm.png)

InsyaAllah pada bagian catatan ini saya akan mencatat bagaimana Langchain membangun pengelompokan pemetaan terhadap LLM sehingga menjadi aplikasi LLM yang berguna.

Jadi apa itu Langchain ? adalah sebuah framework untuk membangun aplikasi LLM. Langchain adalah lapisan orkrestasi dimana mempermudah pengambangan aplikasi LLM dengan menawarkan standarisasi, penggunaan komponen berulang, dan penghubung tugas seperti "pemuatan data", "pengatturan perintah" dan "parsing hasil keluaran".

!!! tip "Bacaan lain Neural Network"
    Saya juga pernah membuat belajar dan hasil coretan saya tentang Langchain dapat dilihat di repositori berikut, [muhammadfarras/Learn-Langchain](https://github.com/muhammadfarras/Learn-LangChain/tree/main)

## Menggunakan LLM pada Langchain

!!! info "Informasi"
    Pada catatan disini saya menggunakan Ollama sebagai penyedia LLM. Sedangkan LLM yang saya gunakan adalah buatan Meta, Llama3.2. Kita bisa menggunakan provider lain atau model lain selama memliki tipe TextGeneration.

    Untuk menggunakan Ollama dengan Langchain lebih lanjut untuk setup dapat dilihat disini [https://python.langchain.com/docs/integrations/llms/ollama/](https://python.langchain.com/docs/integrations/llms/ollama/)

Sebagai pengingat, LLM adalah yang menyetir dibelakang kebanyakan Generative AI Application. Langchain menyediakan 2 interface sederhana agar kita dapat terhubung dengan API yang disediakan oleh provider LLM.

1. ChatModels
2. LLMs

Secara sederhana interface dari LLM menerima perintah dalam bentuk text dan mengirim nilai masukan tersebut ke penyedia model, lalu mengembalikan prediksi dari model sebagai nilai keluaran.

!!! notes "Code"

    ```python
    from langchain_ollama.llms import OllamaLLM

    model = OllamaLLM(model="llama3.2:latest")
    return_value = model.invoke("Assalamualaikum")
    print(return_value)
    # Wa alaykums salam. How can I assist you today?
    ```

### Chat Models

Alternatif lainnya, kita dapat menggunakan ChatModels, interface tersebut membuat kita dapat berinteraksi umpan balik secara terus menerus seperti kita sedang mengobrol. Untuk menggunakannya kita harus memahami apa itu roles.

!!! tip "Apa itu role"

    Tentang role dapat dibaca di [sini](./Other%20Resources/1_roles.md)

!!! notes "Code class dan sample chat model"

    Untuk class `ChatModelsSimplifier` dapat diakses di [ChatModelsSimplifier.py](./lab/ChatModelsSimplifier.py)

    ```python
    from ChatModelsSimplifier import MyLLMChatModel

    my_simple_model = MyLLMChatModel("llama3.2:latest")
    my_simple_model.chat_models("Halo nama saya muhammad farras ma'ruf")
    """
    Assalamu'alaikum warahmatullahi wabarakatuh, Muhammad Farras Ma'ruf.

    Saya senang bertemu dengan Anda. Apakah Anda membutuhkan bantuan atau informasi tentang topik tertentu? Atau mungkin Anda ingin berbicara tentang hobi atau minat Anda?

    Saya di sini untuk membantu dan mendengarkan apa yang Anda inginkan.
    """

    my_simple_model.chat_models("Siapa nama saya ?")
    """
    Saya ingat! Nama Anda adalah Muhammad Farras Ma'ruf.
    """
    ```

Menggunakan ChatModel, dan kita memberikan riwayat percapakan kepada model membuat model mengetahui percakapan sebelumnya.


